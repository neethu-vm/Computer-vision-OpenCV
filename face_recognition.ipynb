{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face recognition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOtBxDYwGcfPE0n/U7EVTAP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neethu-vm/Computer-vision-OpenCV/blob/main/face_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cugj8WksFAC3"
      },
      "source": [
        "# Importing the libraries\n",
        "from PIL import Image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import json\n",
        "import random\n",
        "import cv2\n",
        "from keras.models import load_model\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-nzXhilFRQX",
        "outputId": "dd753d29-3529-4667-b4ac-7275ba974b28"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4QIr_WpFbND"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "model = load_model('/content/drive/MyDrive/neethu project/Neethu project/facerecognition_model1.h5')\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtIPUptAFx8B"
      },
      "source": [
        "# Loading the cascades\n",
        "face_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/neethu project/Neethu project/haarcascade_frontalface_default.xml')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtihe7MuF5fT"
      },
      "source": [
        "def face_extractor(img):\n",
        "    # Function detects faces and returns the cropped face\n",
        "    # If no face detected, it returns the input image\n",
        "    \n",
        "    #gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
        "    \n",
        "    if faces is ():\n",
        "        return None\n",
        "    \n",
        "    # Crop all faces found\n",
        "    for (x,y,w,h) in faces:\n",
        "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
        "        cropped_face = img[y:y+h, x:x+w]\n",
        "\n",
        "    return cropped_face\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "a9mJ5uriF-5y",
        "outputId": "cc1d8e1e-d580-4396-adc2-b371a25f0fa7"
      },
      "source": [
        "# Doing some Face Recognition with the webcam\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "video_capture = cv2.VideoCapture(0)\n",
        "res=(360,240) #resulotion\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V') #codec\n",
        "out = cv2.VideoWriter('video.mp4', fourcc, 20.0, res)\n",
        "while True:\n",
        "    _, frame = video_capture.read()\n",
        "    #canvas = detect(gray, frame)\n",
        "    #image, face =face_detector(frame)\n",
        "    \n",
        "    face=face_extractor(frame)\n",
        "    if type(face) is np.ndarray:\n",
        "        face = cv2.resize(face, (224, 224))\n",
        "        im = Image.fromarray(face, 'RGB')\n",
        "           #Resizing into 128x128 because we trained the model with this image size.\n",
        "        img_array = np.array(im)\n",
        "                    #Our keras model used a 4D tensor, (images x height x width x channel)\n",
        "                    #So changing dimension 128x128x3 into 1x128x128x3 \n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        pred = model.predict(img_array)\n",
        "        print(pred)\n",
        "                     \n",
        "        name=\"None matching\"\n",
        "        \n",
        "        if(pred[0][2]>0.5):\n",
        "            name='Theju'\n",
        "        cv2.putText(frame,name, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
        "    else:\n",
        "        cv2.putText(frame,\"No face found\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
        "    out.write(frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "out.release()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c677f022d1b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#image, face =face_detector(frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mface\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mface_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-0c769637843e>\u001b[0m in \u001b[0;36mface_extractor\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfaces\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'face_cascade' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uChf33FbGcPM"
      },
      "source": [
        "  "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-ya7-ysGE4d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}